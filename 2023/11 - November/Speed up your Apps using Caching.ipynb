{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c25d972-3f53-4a36-b016-9a1d1bd35b6b",
   "metadata": {},
   "source": [
    "### Use Caching to Optimize your Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69a62d-d1d4-4ad0-a536-ddd8b8c10d34",
   "metadata": {},
   "source": [
    "Sometimes, we have functions that are called repeatedly during the lifetime of our application.\n",
    "\n",
    "If those function calls are expensive (either CPU or memory), get called often with the same parameters, and are invariant, then we might have the option of caching the results of these calls instead of re-computing the entire call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33a706-4018-4512-9b51-2f99d17010ae",
   "metadata": {},
   "source": [
    "There are a few things we usually need to ensure before going down that road:\n",
    "\n",
    "- function is invariant (i.e. given the same inputs, it will always return the same output). So a function that is time sensitive, or uses random numbers for example, will not work. You probably also do not want to cache a function that has side effects, so in fact you shoudl probably insist on a pure function.\n",
    "- function arguments need to be hashable (this is because of Python's caching implementations, which uses the argument values as keys in a dictionary)\n",
    "- only useful if the function is repeatedly called with the same values multiple times during the life of our app, and running the function is expensive, in terms of CPU, resource utilization, latency, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc681cf-d7f2-4ec1-8f45-3188180df092",
   "metadata": {},
   "source": [
    "#### Example - From First Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3d4ce-152c-43a2-95e1-12802ac39641",
   "metadata": {},
   "source": [
    "Let's take a quick look at an example of how caching benefits generating the Fibonacci sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac6dee-fd5a-4fd1-a104-37f58e0b2c01",
   "metadata": {},
   "source": [
    "For this example we'll do our own cache mechanism, so you get an understanding of what Python's caching mechanism actually does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0960013f-bdbd-4fd4-80d5-d88f812b3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d617b3-1a4b-4ecb-85b6-e35fa377e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 1, 2, 3, 5, 8, 13, 21, 34, 55, "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(fib(i), end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81973f6-ff41-4a1c-a5ee-8c9d0ca3d8dc",
   "metadata": {},
   "source": [
    "Now let's time this function as `n` increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403e6f30-66a5-400e-8089-1f6839849a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be81c48-f3ee-4e01-95ec-7195d4942c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 0.01 s\n",
      "26 - 0.02 s\n",
      "27 - 0.02 s\n",
      "28 - 0.03 s\n",
      "29 - 0.06 s\n",
      "30 - 0.09 s\n",
      "31 - 0.14 s\n",
      "32 - 0.23 s\n",
      "33 - 0.37 s\n",
      "34 - 0.60 s\n",
      "35 - 0.97 s\n",
      "36 - 1.57 s\n",
      "37 - 2.55 s\n",
      "38 - 4.10 s\n",
      "39 - 6.63 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfe918-ac82-4923-9cc6-6fcc36b71f0a",
   "metadata": {},
   "source": [
    "As you can see, as `n` gets larger, our computation times increase dramatically. \n",
    "\n",
    "In fact, the complexity of this algorithm is exponential, O(2^n)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da551e6-61cf-4377-a2ce-63a1f54e26c2",
   "metadata": {},
   "source": [
    "Why is this happening?\n",
    "\n",
    "The fib function is called repeatedly with the same argument over and over again.\n",
    "\n",
    "Let's put a print statement and see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08806a17-c519-43b5-acdf-50f6458a7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    print(f\"calculating fib({n})\")\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ca2737-6332-4267-8fe6-30f33eae0cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating fib(10)\n",
      "calculating fib(9)\n",
      "calculating fib(8)\n",
      "calculating fib(7)\n",
      "calculating fib(6)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(6)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(7)\n",
      "calculating fib(6)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(8)\n",
      "calculating fib(7)\n",
      "calculating fib(6)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(6)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n",
      "calculating fib(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d2148-429d-40af-a9fe-39f6fdef719b",
   "metadata": {},
   "source": [
    "So we could alter our algorithm to be more efficient (which is what we should do in this particular case). \n",
    "\n",
    "But suppose improving our function's algorithm was not an option. What then?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab828f-19af-4fab-ada1-8fb3612f5e09",
   "metadata": {},
   "source": [
    "Well, if we observe these repeated calls to the `fib()` function, we see that the arguments often have the same values - so, instead of re-computing them, we can cache the results and save the computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881c98a-e5fd-43c6-a826-a27a46ebaff8",
   "metadata": {},
   "source": [
    "Let's start simplistcially by establishing a global dictionary that will hold the value of `n` ad the key, and the result `fib(n)` as the value. Then, when we perform the calculation, we first check to see if `n` is in the dictionary.\n",
    "\n",
    "If it is, we simply return that value (remember that lookups in Python dictionaries are fast, O(1)). If the value is not in the dictionary, we calculate the result, store it in the dictionary, and then return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbcb17eb-a656-473f-8e40-7ff260e62e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    if n in cache:\n",
    "        return cache[n]\n",
    "    print(f\"calculating fib({n})\")\n",
    "    result = fib(n-1) + fib(n-2)\n",
    "    cache[n] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5ff624-7f8c-402c-9d71-6e98095364d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating fib(10)\n",
      "calculating fib(9)\n",
      "calculating fib(8)\n",
      "calculating fib(7)\n",
      "calculating fib(6)\n",
      "calculating fib(5)\n",
      "calculating fib(4)\n",
      "calculating fib(3)\n",
      "calculating fib(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c569b-e895-43e6-b5ab-ab97b61adf1e",
   "metadata": {},
   "source": [
    "See how many less calls we have now?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebddf49-5fc0-41c9-b8fe-8cd8cff0a69b",
   "metadata": {},
   "source": [
    "How about our timings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569b893f-acf4-4dab-aabc-1dab6fa8f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    if n in cache:\n",
    "        return cache[n]\n",
    "    result = fib(n-1) + fib(n-2)\n",
    "    cache[n] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180b1576-516d-4c13-804f-478d141abd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 5.875015631318092e-06 s\n",
      "26 - 5.420297384262085e-07 s\n",
      "27 - 3.33995558321476e-07 s\n",
      "28 - 3.750319592654705e-07 s\n",
      "29 - 2.9098009690642357e-07 s\n",
      "30 - 3.3300602808594704e-07 s\n",
      "31 - 2.9098009690642357e-07 s\n",
      "32 - 2.919696271419525e-07 s\n",
      "33 - 2.9103830456733704e-07 s\n",
      "34 - 3.3294782042503357e-07 s\n",
      "35 - 3.3300602808594704e-07 s\n",
      "36 - 2.92027834802866e-07 s\n",
      "37 - 3.33995558321476e-07 s\n",
      "38 - 2.92027834802866e-07 s\n",
      "39 - 2.92027834802866e-07 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0172f6-4399-4b79-948f-86d656cf79b2",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfb925-cb97-43d3-b5f1-17bf591fc533",
   "metadata": {},
   "source": [
    "Now doing it this way is not exactly very good code - it works, but has a number of drawbacks. That cache is a global \n",
    "variable (which we tend to avoid whenever possible) and the caching is \"baked\" into the `fib()` function itself.\n",
    "\n",
    "To implement this caching mechanism to other functions in our code, we therefore would have to alter the functions themselves - which is far from ideal. And we would have to create an additional global variable for each cached function, cluttering our code needlessly, and also opening ourselves to inadvertent bugs if something outside the caching mechanism tampers with the cache dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcadf1-d8bf-4452-9c16-8c482fabed69",
   "metadata": {},
   "source": [
    "Instead, we can actually use a closure to perform all this work, and by setting it up as a decorator we end up with a solution that is reusable and properly applies the decomposition concept I covered in an earlier video.\n",
    "\n",
    "For simplicity, I will only handle caching arbitrary functions that use positional arguments only, but the same idea can be extended to functions that also use keyword-only arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d630bc-97d7-4a1e-8d34-b4ef4474c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(fn):\n",
    "    data_cache = {}\n",
    "\n",
    "    def inner(*args):\n",
    "        key = tuple(args)\n",
    "        if key in data_cache:\n",
    "            return data_cache[key]\n",
    "        result = fn(*args)\n",
    "        data_cache[key] = result\n",
    "        return result\n",
    "        \n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddd9a3-797b-476a-8de4-c2095345e89c",
   "metadata": {},
   "source": [
    "Now, let's try using this decorator for our `fib()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e253a3-0efd-4914-808e-163d40da3094",
   "metadata": {},
   "source": [
    "This was our original function whose implementation we ended up modifying in order to add caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595eccc4-1bd0-49be-bfc3-cd0ac0bccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0651e-92cb-4e68-ad93-27c3bae6a2ec",
   "metadata": {},
   "source": [
    "To implement the cache now, we only need to decorate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaa918ad-e0ff-4b7f-865a-f9f73de21fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eba5df-6626-4656-b28f-975fe4af46c7",
   "metadata": {},
   "source": [
    "And now let's time things again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "762c8efe-6211-4219-8d7c-68dca71d4c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 9.374984074383974e-06 s\n",
      "26 - 7.500057108700275e-07 s\n",
      "27 - 8.330098353326321e-07 s\n",
      "28 - 7.080379873514175e-07 s\n",
      "29 - 5.839974619448185e-07 s\n",
      "30 - 5.410402081906796e-07 s\n",
      "31 - 4.5797787606716156e-07 s\n",
      "32 - 5.409820005297661e-07 s\n",
      "33 - 5.839974619448185e-07 s\n",
      "34 - 7.079797796905041e-07 s\n",
      "35 - 5.830079317092896e-07 s\n",
      "36 - 5.839974619448185e-07 s\n",
      "37 - 4.5797787606716156e-07 s\n",
      "38 - 4.5797787606716156e-07 s\n",
      "39 - 5.00003807246685e-07 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564b4d7-7285-4925-866b-9563bd48aa7d",
   "metadata": {},
   "source": [
    "So, this is how we can implement caching from first principles. You'll also see why I said earlier that the arguments to the function being cached need to be hashable - they end up (as a tuple) as the **keys** in our cache dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9f970-8d44-4f9e-901a-da0111f9bd04",
   "metadata": {},
   "source": [
    "#### Python's LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080eed66-0b82-4f2a-896a-430d4c2bc1a6",
   "metadata": {},
   "source": [
    "We don't have to implement this cache mechanism ourselves. In fact, the way we did it has some serious limitations.\n",
    "\n",
    "For example, we do not handle caching functions which have keyword-only arguments. Also, our cache size is unlimited, which may not be something we want - we may want to only cache a fixed number of \"calls\" - a common approach here is to limit the cache size, and once the cache goes beyond that limit, start removing the \"oldest\" (least recently used = LRU) items from the cache.\n",
    "\n",
    "If you want to know more about LRU caching in general terms, and other cache replacement algorithms, here is the Wikipedia link for it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464bee2-6043-4d29-b164-ba8d3d2e8073",
   "metadata": {},
   "source": [
    "[https://en.wikipedia.org/wiki/Cache_replacement_policies](https://en.wikipedia.org/wiki/Cache_replacement_policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8eb06-d5ef-4617-8134-f83dcf0fea5d",
   "metadata": {},
   "source": [
    "Python implements this LRU (least recently used) cache replacement algorithm, in the `functools` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d68c010e-6aa9-4fdf-9b40-1b36fb991913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae5030-1e74-47f2-9a2a-3f5c880dd309",
   "metadata": {},
   "source": [
    "And let's use it with our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceaa157f-dace-4b81-838d-407e370b883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8796cdd-28e7-46dd-b841-262caeff406d",
   "metadata": {},
   "source": [
    "This establishes an LRU cache for our `fib()` function, with a default max size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ff5063-d0ed-44d4-b889-f32212e71a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 1.2166041415184736e-05 s\n",
      "26 - 4.169996827840805e-07 s\n",
      "27 - 2.92027834802866e-07 s\n",
      "28 - 2.919696271419525e-07 s\n",
      "29 - 2.9103830456733704e-07 s\n",
      "30 - 2.500019036233425e-07 s\n",
      "31 - 2.500019036233425e-07 s\n",
      "32 - 2.0797597244381905e-07 s\n",
      "33 - 2.500019036233425e-07 s\n",
      "34 - 2.500019036233425e-07 s\n",
      "35 - 2.9098009690642357e-07 s\n",
      "36 - 2.0803418010473251e-07 s\n",
      "37 - 2.0902371034026146e-07 s\n",
      "38 - 2.500019036233425e-07 s\n",
      "39 - 2.0797597244381905e-07 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c228b47-30d8-4b0b-9e0a-069e489ff327",
   "metadata": {},
   "source": [
    "We can easily change the cache size to any specific value, including unlimited this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a138333-5544-4a22-90f0-b9b0d417b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbae8a4a-6ad4-4d80-874c-16e1477c1472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 5.62501372769475e-06 s\n",
      "26 - 4.159519448876381e-07 s\n",
      "27 - 2.500019036233425e-07 s\n",
      "28 - 2.500019036233425e-07 s\n",
      "29 - 2.500019036233425e-07 s\n",
      "30 - 2.0902371034026146e-07 s\n",
      "31 - 2.919696271419525e-07 s\n",
      "32 - 2.500019036233425e-07 s\n",
      "33 - 2.0797597244381905e-07 s\n",
      "34 - 2.0797597244381905e-07 s\n",
      "35 - 2.500019036233425e-07 s\n",
      "36 - 2.08965502679348e-07 s\n",
      "37 - 2.0902371034026146e-07 s\n",
      "38 - 2.9098009690642357e-07 s\n",
      "39 - 2.500019036233425e-07 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f118206d-3997-4a7c-a46e-e10a34f32d2c",
   "metadata": {},
   "source": [
    "And for a limited cache size, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c1b34d-f643-4186-af29-8041f69dc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=20)\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f49fb9d-61ef-4c2c-9531-0c17d7647a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 6.417045369744301e-06 s\n",
      "26 - 1.00000761449337e-06 s\n",
      "27 - 4.1601015254855156e-07 s\n",
      "28 - 5.00003807246685e-07 s\n",
      "29 - 2.919696271419525e-07 s\n",
      "30 - 2.92027834802866e-07 s\n",
      "31 - 2.9098009690642357e-07 s\n",
      "32 - 2.500019036233425e-07 s\n",
      "33 - 3.3300602808594704e-07 s\n",
      "34 - 2.500019036233425e-07 s\n",
      "35 - 3.750319592654705e-07 s\n",
      "36 - 2.9098009690642357e-07 s\n",
      "37 - 2.500019036233425e-07 s\n",
      "38 - 2.919696271419525e-07 s\n",
      "39 - 2.500019036233425e-07 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6e40d-695d-4dc8-b0c2-a48fcd8fdf11",
   "metadata": {},
   "source": [
    "For our `fib()` example, if you look at the code closely, and the trace outputs we had earlier, you'll realize that in fact we only need to ever cache the last 2 calls - so we could limit our LRU cache to just two elements, without losing the speedup benefits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d42a40e9-9dc6-40b9-96a2-81f53c637d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=2)\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6a78337-98f5-457f-8eb6-023f017487ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 0.000801375019364059 s\n",
      "26 - 0.00030200002947822213 s\n",
      "27 - 0.0004160410026088357 s\n",
      "28 - 0.0005925829755142331 s\n",
      "29 - 0.00079158297739923 s\n",
      "30 - 0.0010942919761873782 s\n",
      "31 - 0.0016196249634958804 s\n",
      "32 - 0.002049707982223481 s\n",
      "33 - 0.0027969160000793636 s\n",
      "34 - 0.00412495800992474 s\n",
      "35 - 0.005773082957603037 s\n",
      "36 - 0.007761000015307218 s\n",
      "37 - 0.01030524994712323 s\n",
      "38 - 0.013624083949252963 s\n",
      "39 - 0.018959375040140003 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f599349-2b00-4e4d-a246-a2767deab243",
   "metadata": {},
   "source": [
    "Any lower than that however, and things won't work as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5804a37f-64c5-4ff1-8881-198b6900e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "024d8649-0ad5-4362-a521-9856a304dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 0.020892457978334278 s\n",
      "26 - 0.012763917038682848 s\n",
      "27 - 0.02029274997767061 s\n",
      "28 - 0.032628499960992485 s\n",
      "29 - 0.05313491600099951 s\n",
      "30 - 0.08700279204640538 s\n",
      "31 - 0.13940141699276865 s\n",
      "32 - 0.22385312500409782 s\n",
      "33 - 0.3612438749987632 s\n",
      "34 - 0.5826868750154972 s\n",
      "35 - 0.9421670840238221 s\n",
      "36 - 1.524265291984193 s\n",
      "37 - 2.4616684170323424 s\n",
      "38 - 3.987549334007781 s\n",
      "39 - 6.533424041990656 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f983c-9633-4420-ae2a-56ce872ee300",
   "metadata": {},
   "source": [
    "#### Unbounded LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984fa13-2830-4d34-ba66-72ccf009bd56",
   "metadata": {},
   "source": [
    "We just saw that we can use `maxsize=None` to create an unbounded LRU cache.\n",
    "\n",
    "Python also provides a simpler syntax to do the same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4c791f3-c0a3-4181-a04e-045f038be885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f019ce52-9f93-4b6b-afba-7ab8cfe5e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64afa55c-5fea-4525-88ab-bcec4a0f2b58",
   "metadata": {},
   "source": [
    "Then can be equivalently defined this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deaa4bcd-ab60-459e-8c7c-6c54cb59c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91c1f4fd-b16b-4fcf-a8b2-6f1e5f6080be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 - 5.957961548119783e-06 s\n",
      "26 - 3.7497375160455704e-07 s\n",
      "27 - 2.500019036233425e-07 s\n",
      "28 - 3.750319592654705e-07 s\n",
      "29 - 2.0902371034026146e-07 s\n",
      "30 - 2.0797597244381905e-07 s\n",
      "31 - 2.0797597244381905e-07 s\n",
      "32 - 2.0902371034026146e-07 s\n",
      "33 - 1.66997779160738e-07 s\n",
      "34 - 2.0797597244381905e-07 s\n",
      "35 - 2.500019036233425e-07 s\n",
      "36 - 2.0797597244381905e-07 s\n",
      "37 - 2.500019036233425e-07 s\n",
      "38 - 2.0902371034026146e-07 s\n",
      "39 - 2.0797597244381905e-07 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 40):\n",
    "    elapsed = timeit(f\"fib({i})\", globals=globals(), number=1)\n",
    "    print(f\"{i} - {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23530e9-174f-4a4f-b295-a20186e0954e",
   "metadata": {},
   "source": [
    "But of course, in this case, we would be better off setting up an LRU cache with a size of 2. However, for cases where you need an unlimited cache, then using `@cache` is pretty easy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3880022-183d-4a9b-b8d7-d6c87a633682",
   "metadata": {},
   "source": [
    "#### Some Finer Details and Caveats on LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c631b-6443-48c2-9cb5-9e48764840e9",
   "metadata": {},
   "source": [
    "There are a few finer points that you may want to be aware of when using the LRU cache mechanism provided by Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f2b93-6eee-4ddf-9c3d-1faf97efbf2b",
   "metadata": {},
   "source": [
    "Let's say we have this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f397bdae-3986-4820-ac98-a99a07b7e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a, b, c):\n",
    "    print(f\"computing result for {a=}, {b=}, {c=}\")\n",
    "    return a + b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ac00425-9ff8-4f1e-8639-729e4b01f884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing result for a=1, b=2, c=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c288d67a-3852-406c-a2c8-2f039a799d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing result for a=1, b=2, c=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f547c-31d8-451a-8930-77db6bb3c289",
   "metadata": {},
   "source": [
    "Now let's apply an LRU cache to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3ef7c42-f82f-4ef2-be1e-5fb44fb22d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def func(a, b, c):\n",
    "    print(f\"computing result for {a=}, {b=}, {c=}\")\n",
    "    return a + b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16c8efd1-5dc2-49ff-8192-cc4f1bc90f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing result for a=1, b=2, c=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55bf7623-6cd1-4d0f-bda2-c3b4114abee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb3767-c7e3-4643-94f5-57e493a9d13f",
   "metadata": {},
   "source": [
    "As you can see, we got a cache \"hit\", and the computation was not performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cfab3f-1fb9-453a-a6e7-5b14c8c720ce",
   "metadata": {},
   "source": [
    "However, as you know, we can choose to pass values using named arguments as well.\n",
    "\n",
    "Let's see what happens when we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10fd0a46-c20e-4c55-888a-34d19bf37b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing result for a=1, b=2, c=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(a=1, b=2, c=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe527d-ba66-4326-946e-9d1426a2b9ae",
   "metadata": {},
   "source": [
    "As you can see, this was a cache \"miss\", and we incurred the re-computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a24f6-d769-44ed-bf63-ca934bb40e94",
   "metadata": {},
   "source": [
    "Now the second time around, we'll get a cache hit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da4ccaed-3395-49a0-8dc2-4329f9348798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(a=1, b=2, c=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536eb37-54d6-48f5-9bb2-20ff44a60fb0",
   "metadata": {},
   "source": [
    "But, if we change the order of the arguments, we'll get a cache miss again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45e51a4b-afdb-493d-8a91-1ffbcd84d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing result for a=1, b=2, c=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(b=2, a=1, c=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b481b60-d4ae-44da-b6d8-025bd309d662",
   "metadata": {},
   "source": [
    "But now, both ways of calling the function (with the same values essentially) are cached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1311599c-db75-4247-a5a5-d689462d176e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(a=1, b=2, c=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d373d2b-90cc-4796-95f9-84db85798831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(b=2, a=1, c=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd7696-e6b9-435e-8552-4e8fc2ebf2f8",
   "metadata": {},
   "source": [
    "#### Caching Class Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cf461-40d7-4aa1-8d48-5ffa5540f7b1",
   "metadata": {},
   "source": [
    "Sometimes we need to apply the same cache principle to properties (especially calculated properties) in our classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eceedf-b4d5-4edb-aa7d-71dbcfcf051f",
   "metadata": {},
   "source": [
    "We can certainly do it from first principles, like this for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69602c6b-1061-419b-bfea-ab8632c4cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "\n",
    "    @property\n",
    "    def area(self):\n",
    "        return pi * (self._radius ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80416d4-d8f9-4cee-af69-a6b53a6316ec",
   "metadata": {},
   "source": [
    "So, the calculated `area` property is completely uncached, and this is the performance if we would need to repeatedly call this property in our app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aff5f6f1-cd1e-4e9c-ac11-3fecb0e7a1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07789866701932624"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(3)\n",
    "\n",
    "timeit(\"c.area\", globals=globals(), number=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a2cd6-2864-4443-abd5-bf49ddd8351d",
   "metadata": {},
   "source": [
    "Now, let's implement caching from first principles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f55b7eae-9850-4c59-880b-dac958b87304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "        self._area = None\n",
    "\n",
    "    @property\n",
    "    def area(self):\n",
    "        if self._area is None:\n",
    "            self._area = pi * (self._radius ** 2)\n",
    "        return self._area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5beac89-28c4-41c0-818c-cef995dd1f6d",
   "metadata": {},
   "source": [
    "And let's time it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c347091-3a1d-4c68-a400-ea16e38a7ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05554583400953561"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(3)\n",
    "\n",
    "timeit(\"c.area\", globals=globals(), number=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78986af0-9f11-42cd-9813-2ee2c9489ba6",
   "metadata": {},
   "source": [
    "Although this solution works, it suffers from the same problem we saw earlier - we need to \"bake\" the caching into the property itself. Not the end of the world, but it would be nice if we could just decorate our property just like we did with the LRU cache.\n",
    "\n",
    "And in fact, Python provides this with the `@cached_property` decorator in the `functools` module also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d704746e-3798-43b6-9ff5-a8f24c9fe89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cached_property\n",
    "\n",
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "        self._area = None\n",
    "\n",
    "    @cached_property\n",
    "    def area(self):\n",
    "        return pi * (self._radius ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d52ae40-e633-4fcc-a55a-72f002deec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024079292023088783"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(3)\n",
    "\n",
    "timeit(\"c.area\", globals=globals(), number=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764fcc0-f8c2-49a1-aeba-3ead386985a2",
   "metadata": {},
   "source": [
    "#### Caveats of Cached Properties and Mutability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ce036-f837-4918-bdfc-c202f5249ceb",
   "metadata": {},
   "source": [
    "Now, this approach here works because our `Circle` class is immutable (by convention). We assume that since we have set our radius to be private (by convention, using that leading underscore), that the radius will never change over the lifetime of our `Circle(3)` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9510a-7866-4ecc-a2d4-cc855f9a04fb",
   "metadata": {},
   "source": [
    "If the radius does change for some reason, we'll run into issues (both with our own approach, and with the `cached_property` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7824fc3d-dff2-4bd9-b97b-78d7004f382a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.274333882308138"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(3)\n",
    "c.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f61aba-3f1e-459a-8153-237baf6d80b6",
   "metadata": {},
   "source": [
    "Now let's change that radius (even though we should not):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d98ca577-208b-4842-96ab-8f050b68be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c._radius = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b787aabf-4f02-4093-9428-bcd822fe231a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.274333882308138"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a403db-b2ab-4d55-beef-516a38582665",
   "metadata": {},
   "source": [
    "As you can see, we get the wrong value for the area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d7481-0e52-4680-ac62-34d33e4be6ea",
   "metadata": {},
   "source": [
    "So can we deal with this, and how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f2f12-5dc4-462d-981e-0b27b2c32538",
   "metadata": {},
   "source": [
    "let's look at our first principle approach first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93f358e5-5828-40a8-8326-86cc7ac85a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "        self._area = None\n",
    "\n",
    "    @property\n",
    "    def area(self):\n",
    "        if self._area is None:\n",
    "            self._area = pi * (self._radius ** 2)\n",
    "        return self._area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9e16d-7c17-4294-bf68-6fe615388767",
   "metadata": {},
   "source": [
    "What we are going to do here is make the Circle class mutable by controlling how the radius value gets set, so we'll implement both a getter and a setter for our radius. \n",
    "\n",
    "In the setter, we'll detect whether the radius has changed, and if so, we'll \"invalidate\" the cache (i.e. clear the cache) for the `area` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e32b3278-51ec-4026-aad6-c6db41fdb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "        self._area = None\n",
    "\n",
    "    @property\n",
    "    def radius(self):\n",
    "        return self._radius\n",
    "\n",
    "    @radius.setter\n",
    "    def radius(self, value):\n",
    "        if self._radius != value:\n",
    "            self._area = None\n",
    "        self._radius = value\n",
    "    \n",
    "    @property\n",
    "    def area(self):\n",
    "        if self._area is None:\n",
    "            self._area = pi * (self._radius ** 2)\n",
    "        return self._area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe27cd2-92ec-46c1-ab77-89661db2e250",
   "metadata": {},
   "source": [
    "Now let's see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ee70de7-557d-47c8-9dab-57e12c6099fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(1)\n",
    "c.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91085f60-9f35-4175-b048-0da13cbfd129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.566370614359172"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.radius = 2\n",
    "c.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397df55-aae0-46cf-8877-58d918fc7feb",
   "metadata": {},
   "source": [
    "As you can see, we now have a way to control when the cache for area gets cleared, so we get the correct result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee4389-939f-492a-ae04-8048418644ff",
   "metadata": {},
   "source": [
    "How about clearing the cache when using `cached_property`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb029e-21fe-47f9-a154-4f1390b4a6b5",
   "metadata": {},
   "source": [
    "We do so, by deleting the property - kinf of weird, but this works because the `cached_property` decorator will re-created the property if needed.\n",
    "\n",
    "So let's see this - much simpler to understand seeing an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44f508-92f0-4f16-84c9-9ea9689a03eb",
   "metadata": {},
   "source": [
    "This was our original implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07d3617b-2ff8-45c6-a76a-e8445ce6b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "\n",
    "    @cached_property\n",
    "    def area(self):\n",
    "        return pi * (self._radius ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a83a8d-1077-4c5a-ae25-40a096f7cf18",
   "metadata": {},
   "source": [
    "Let's add the radius property and invalidate the cache as needed in the radius setter, just like we did in our first principle example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20da60e6-65e8-4311-abba-fcdeab0520de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle():\n",
    "    def __init__(self, radius):\n",
    "        self._radius = radius\n",
    "        self._area = None\n",
    "\n",
    "    @property\n",
    "    def radius(self):\n",
    "        return self._radius\n",
    "\n",
    "    @radius.setter\n",
    "    def radius(self, value):\n",
    "        if self._radius != value:\n",
    "            del self.area\n",
    "        self._radius = value\n",
    "        \n",
    "    @cached_property\n",
    "    def area(self):\n",
    "        return pi * (self._radius ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d07e0bca-a2cd-4a10-9832-c1474e298bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(1)\n",
    "c.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e721380c-279e-4533-aee2-6f6137c8723b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.566370614359172"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.radius = 2\n",
    "c.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f49ea41-b48a-49f2-8c46-9aad65cf1692",
   "metadata": {},
   "source": [
    "As you can see, we get the same effect now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1b546-4ed6-4c58-8ae0-7fb0de17f2a9",
   "metadata": {},
   "source": [
    "#### Caching Class Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3de2ad-d17f-40fb-8ec5-127234240fbe",
   "metadata": {},
   "source": [
    "What about caching class methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d3354-ed3f-469e-88ed-1d35c1e6f81a",
   "metadata": {},
   "source": [
    "This can certainly be done as well using either `cache` or `lru_cache`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c568bd-a81f-45a5-a6d5-3bf21fd47514",
   "metadata": {},
   "source": [
    "However, we need to understand that unlike `cached_property`, that establishes a cache at the instance level, caching a method using `cache` or `lru_cache` establishes a cache at the **class** level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c5791-db3c-4720-9dcc-41f8361e7c44",
   "metadata": {},
   "source": [
    "It's mostly transparent to us, as the end-users, but it does mean we have to handle cache invalidation a bit differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e46a73-3a6a-457c-bec4-903eaab6b645",
   "metadata": {},
   "source": [
    "Instead of using a property for the area, let's just make it a method, and see how we can deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79eef791-f724-4ce2-9fa7-aabff9608fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle:\n",
    "    def __init__(self, r):\n",
    "        self.r = r\n",
    "\n",
    "    @cache\n",
    "    def area(self):\n",
    "        print(f\"calculating area for {self.r=}\")\n",
    "        return pi * (self.r ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4409613-c1aa-4726-b485-59be0258ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating area for self.r=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Circle(1)\n",
    "c.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e3d3d37-fa00-45f6-8225-0214957759d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.r = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bb22d1b-caf6-4aa9-ab83-461098d97df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1a4ea-67a9-473a-be7e-d7b7e01462e0",
   "metadata": {},
   "source": [
    "As you can see, we have the wrong result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8140db-2ebd-46c7-a2b4-acfd80a3809f",
   "metadata": {},
   "source": [
    "Observe that if we have two instances of the same radius circles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c744bda-2c99-476e-87d8-6ff84a8b9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Circle(1)\n",
    "c2 = Circle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ece4b12-0276-4464-959d-121d7c81cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 == c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066816f-e8f4-4768-bfd1-4ca0daa0771d",
   "metadata": {},
   "source": [
    "So, the two circles are not equal to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2078cdc-1007-48d8-b868-d8d556a567a4",
   "metadata": {},
   "source": [
    "And now let's see how the cache mechanism works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbf9de45-f1d5-4b13-87ab-a67030eb8511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating area for self.r=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53588b5a-a3d9-4640-9221-c60d89e7f6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating area for self.r=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c5303-2a23-4488-989a-82921b9f5c81",
   "metadata": {},
   "source": [
    "As might be expected, we get two cache misses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292b839-b95e-4ecc-998b-e76a6f7810c4",
   "metadata": {},
   "source": [
    "So, we can do something about not only this (recalculating the area when in fact the radiuses are the same), but also invalidting the cache when the radius has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6a6b2-34f3-4f6c-b622-6c468fb88316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b883620b-81e7-4d95-893b-f6abf802c714",
   "metadata": {},
   "source": [
    "We can do this by implementing the `__eq__` and `__hash__` methods to define what consitutes equality, and to make sure that a radius change (in this case) results in objects no longer being equal - something the cache will pick up on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "840142c0-b5d1-4c32-a7ea-66a0ff601f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Circle:\n",
    "    def __init__(self, r):\n",
    "        self.r = r\n",
    "\n",
    "    @cache\n",
    "    def area(self):\n",
    "        print(f\"calculating area for {self.r=}\")\n",
    "        return pi * (self.r ** 2)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.r == other.r\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6825b3c-7c0b-4180-8cf4-1ba2c5561f10",
   "metadata": {},
   "source": [
    "Now we can see that we have equality the way we probably want it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19d2ce26-6c45-4e49-bee3-177d1d0f3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Circle(1)\n",
    "c2 = Circle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e367725e-cd86-44ac-ba03-9f8ad100c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 == c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0af68-9974-4cac-8e46-c4af4cdfa0c1",
   "metadata": {},
   "source": [
    "And let's see how the caching works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa77f8fe-e475-41fe-b004-d3af3773dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating area for self.r=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a33ce4b1-d218-4664-91fd-f489af2eedf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a7118-af4d-4976-9672-5db9ca437428",
   "metadata": {},
   "source": [
    "As you can see, we had a cache hit when calculating the area on the second instance. \n",
    "\n",
    "That is because the first instance is **equal** to the second instance - so, from the cache perspective, it already had the cached value,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953bc153-8369-441d-a1a0-bb293a41dc50",
   "metadata": {},
   "source": [
    "Let's mutate the class now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "645eea5e-0bc7-496a-844d-84ed335b64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.r = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba1fb6bb-650b-4c70-8d53-ddcb9eb3d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 == c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19933440-0473-48d0-90c1-b30b6460197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating area for self.r=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.566370614359172"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c65a9-0c50-4811-ac85-ce63f2fd1d48",
   "metadata": {},
   "source": [
    "As you can see, we got a cache miss and the correct result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ec43c-799d-47ba-9366-d7473a483f69",
   "metadata": {},
   "source": [
    "And, if we call this on the second instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffe59b4d-2ef4-4c7b-8bc8-89ecc0caa5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating area for self.r=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af6a86-9c5b-459e-97da-d62fd7bcf53f",
   "metadata": {},
   "source": [
    "We also get a cache miss.\n",
    "\n",
    "When we invalidated the cache for `c1`, the cache entry that contained the area for a radius of `1`, we also happened to remove the entry that got used for `c2.area()` the first time around, hence the cache miss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b25f1-6216-4575-ad99-3919d697a088",
   "metadata": {},
   "source": [
    "#### Other Types of Caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85697bd9-a3bd-44cd-829d-f4aa254569bf",
   "metadata": {},
   "source": [
    "If the LRU replacement policy is not what you are looking for, then you'll either have to implement something yourself from first principles, or you could make use of third party libraries which have already done the hard work for you.\n",
    "\n",
    "For example this popular library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc79a85-84b1-46c0-9aa2-3ae5daa9c55e",
   "metadata": {},
   "source": [
    "[https://github.com/tkem/cachetools/](https://github.com/tkem/cachetools/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
