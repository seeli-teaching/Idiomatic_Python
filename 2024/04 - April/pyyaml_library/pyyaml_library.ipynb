{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa17350e-1fbf-4100-b532-50d4aaf59fa2",
   "metadata": {},
   "source": [
    "# The `pyyaml` Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dae695-b314-4eb7-8a48-d4a08d77f797",
   "metadata": {},
   "source": [
    "Often, configurations are stored in YAML files (a superset of JSON).\n",
    "\n",
    "Reading those configs in our Python app is dead easy with the `pyyaml` library. Of course, you're not limited to config files, you can also just as easily read (and write) docker compose yaml files, etc.\n",
    "\n",
    "This library can be found here:\n",
    "\n",
    "[https://pyyaml.org/](https://pyyaml.org/)\n",
    "\n",
    "and can be pip installed via:\n",
    "\n",
    "```bash\n",
    "pip install pyyaml\n",
    "```\n",
    "\n",
    "For this notebook, you'll find two companion yaml file, one named `config.yaml`, and the other `docker-compose.yaml`.\n",
    "\n",
    "Let's look at how to read the `config.yaml` file and access data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aead385f-4b3e-49bb-a784-94ae2ada3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b5a83-a2e5-407f-af18-3b8e26a2df0b",
   "metadata": {},
   "source": [
    "Although the yaml library provides a `load()` function, it is not considered safe, specifically when loading yaml data that you are not 100% in control of (there are ways for yaml files to cause code to execute) - for that reason, `safe_load()` is the preferred method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efce71d-2481-4556-9865-1bdf6f8e3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba1857-cd52-4787-9077-dff1506420fe",
   "metadata": {},
   "source": [
    "And let's see what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788a73ba-e430-4659-8c46-1f7f51a574c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observer': {'latitude': 33.4,\n",
       "  'longitude': -111.8,\n",
       "  'horizon_file': 'data/horizon.csv'},\n",
       " 'catalog': {'file': 'data/dso_catalog.csv',\n",
       "  'categories': ['emission_nebula',\n",
       "   'reflection_nebula',\n",
       "   'hii_regions',\n",
       "   'galaxies',\n",
       "   'galaxy_clusters']}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac6e13-f7c2-4245-91c5-72120b0ac89b",
   "metadata": {},
   "source": [
    "From this point on, we can use however we want, possibly even loading it into a Pydantic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff32fed8-f283-4c72-ae69-b622fee340f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ObserverSettings(BaseModel):\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    horizon_file: str | None = None\n",
    "\n",
    "class CatalogSettings(BaseModel):\n",
    "    file: str\n",
    "    categories: list[str]\n",
    "    \n",
    "class Settings(BaseModel):\n",
    "    observer: ObserverSettings\n",
    "    catalog: CatalogSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafeffe4-f4e9-486c-a409-695c32f07b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Settings(observer=ObserverSettings(latitude=33.4, longitude=-111.8, horizon_file='data/horizon.csv'), catalog=CatalogSettings(file='data/dso_catalog.csv', categories=['emission_nebula', 'reflection_nebula', 'hii_regions', 'galaxies', 'galaxy_clusters']))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = Settings.model_validate(config)\n",
    "settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee82a3b-286e-4c94-971a-1bfb5271ecfc",
   "metadata": {},
   "source": [
    "One very interesting thing about yaml is that it is techncially a superset of JSON - so valid JSON also happens to be valid YAML.\n",
    "\n",
    "As an example of this, you'll find a file in this folder named `nobel_prizes.json`. It is JSON, and we could certainly load it up into a Python dictionary structure using the `json.load` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5cbf16f-bcd2-45c0-a939-0ea922c6df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"nobel_prizes.json\") as f:\n",
    "    data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c346b7-3ef1-44d0-a831-58f8fc0bf3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 2023,\n",
       "  'category': 'chemistry',\n",
       "  'overallMotivation': None,\n",
       "  'laureates': [{'id': 1029,\n",
       "    'firstname': 'Moungi',\n",
       "    'surname': 'Bawendi',\n",
       "    'motivation': '\"for the discovery and synthesis of quantum dots\"',\n",
       "    'share': 3},\n",
       "   {'id': 1030,\n",
       "    'firstname': 'Louis',\n",
       "    'surname': 'Brus',\n",
       "    'motivation': '\"for the discovery and synthesis of quantum dots\"',\n",
       "    'share': 3},\n",
       "   {'id': 1031,\n",
       "    'firstname': 'Aleksey',\n",
       "    'surname': 'Yekimov',\n",
       "    'motivation': '\"for the discovery and synthesis of quantum dots\"',\n",
       "    'share': 3}]},\n",
       " {'year': 2023,\n",
       "  'category': 'economics',\n",
       "  'overallMotivation': None,\n",
       "  'laureates': [{'id': 1034,\n",
       "    'firstname': 'Claudia',\n",
       "    'surname': 'Goldin',\n",
       "    'motivation': '\"for having advanced our understanding of women’s labour market outcomes\"',\n",
       "    'share': 1}]},\n",
       " {'year': 2023,\n",
       "  'category': 'literature',\n",
       "  'overallMotivation': None,\n",
       "  'laureates': [{'id': 1032,\n",
       "    'firstname': 'Jon',\n",
       "    'surname': 'Fosse',\n",
       "    'motivation': '\"for his innovative plays and prose which give voice to the unsayable\"',\n",
       "    'share': 1}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json[\"prizes\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7f808-f9e9-41e8-953e-c246e8662942",
   "metadata": {},
   "source": [
    "But interestingly enough, you can also load this same data using `pyyaml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae1dfca-834c-4f5c-bb0e-9e33a3515ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nobel_prizes.json\") as f:\n",
    "    data_yaml = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351ff945-221c-4338-8094-9104a2be0bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 2023,\n",
       "  'category': 'chemistry',\n",
       "  'overallMotivation': None,\n",
       "  'laureates': [{'id': 1029,\n",
       "    'firstname': 'Moungi',\n",
       "    'surname': 'Bawendi',\n",
       "    'motivation': '\"for the discovery and synthesis of quantum dots\"',\n",
       "    'share': 3},\n",
       "   {'id': 1030,\n",
       "    'firstname': 'Louis',\n",
       "    'surname': 'Brus',\n",
       "    'motivation': '\"for the discovery and synthesis of quantum dots\"',\n",
       "    'share': 3},\n",
       "   {'id': 1031,\n",
       "    'firstname': 'Aleksey',\n",
       "    'surname': 'Yekimov',\n",
       "    'motivation': '\"for the discovery and synthesis of quantum dots\"',\n",
       "    'share': 3}]},\n",
       " {'year': 2023,\n",
       "  'category': 'economics',\n",
       "  'overallMotivation': None,\n",
       "  'laureates': [{'id': 1034,\n",
       "    'firstname': 'Claudia',\n",
       "    'surname': 'Goldin',\n",
       "    'motivation': '\"for having advanced our understanding of women’s labour market outcomes\"',\n",
       "    'share': 1}]},\n",
       " {'year': 2023,\n",
       "  'category': 'literature',\n",
       "  'overallMotivation': None,\n",
       "  'laureates': [{'id': 1032,\n",
       "    'firstname': 'Jon',\n",
       "    'surname': 'Fosse',\n",
       "    'motivation': '\"for his innovative plays and prose which give voice to the unsayable\"',\n",
       "    'share': 1}]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yaml[\"prizes\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898930d4-c6a7-4d9b-a4f8-f93fffc72437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json == data_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c162c4-054f-4925-9982-8f563f4b7755",
   "metadata": {},
   "source": [
    "As you can see, identical results.\n",
    "\n",
    "Now, I am not suggesting you stop using `json.load` to parse JSON data and switch to `pyyaml` instead - the json loader is faster since it has less work to do - I just wanted to point out that since JSON is a subset of YAML, a YAML parser is totally able to parse JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f502b-2b17-4474-9c53-0f959acd1f64",
   "metadata": {},
   "source": [
    "Of course, we could further load this data into a Pydantic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a544e2-a8c7-4677-9fbb-3b30d4e01fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laureate(BaseModel):\n",
    "    id: int\n",
    "    firstname: str | None = None\n",
    "    surname: str | None = None\n",
    "    motivation: str | None = None\n",
    "    share: int | None = None\n",
    "\n",
    "class Prize(BaseModel):\n",
    "    year: int | None = None\n",
    "    category: str | None = None\n",
    "    overallMotivation: str | None = None\n",
    "    laureates: list[Laureate] = []\n",
    "\n",
    "class Prizes(BaseModel):\n",
    "    prizes: list[Prize]\n",
    "\n",
    "data_pydantic = Prizes.model_validate(data_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85eaa21-1b2a-49c5-baf2-1fea41ee9f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prize(year=2023, category='chemistry', overallMotivation=None, laureates=[Laureate(id=1029, firstname='Moungi', surname='Bawendi', motivation='\"for the discovery and synthesis of quantum dots\"', share=3), Laureate(id=1030, firstname='Louis', surname='Brus', motivation='\"for the discovery and synthesis of quantum dots\"', share=3), Laureate(id=1031, firstname='Aleksey', surname='Yekimov', motivation='\"for the discovery and synthesis of quantum dots\"', share=3)]),\n",
       " Prize(year=2023, category='economics', overallMotivation=None, laureates=[Laureate(id=1034, firstname='Claudia', surname='Goldin', motivation='\"for having advanced our understanding of women’s labour market outcomes\"', share=1)]),\n",
       " Prize(year=2023, category='literature', overallMotivation=None, laureates=[Laureate(id=1032, firstname='Jon', surname='Fosse', motivation='\"for his innovative plays and prose which give voice to the unsayable\"', share=1)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pydantic.prizes[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9a1b4-17cc-4d7f-a104-a0fd57770cec",
   "metadata": {},
   "source": [
    "## Writing YAML back to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf23df-7fe4-425f-9aef-407410bf5b37",
   "metadata": {},
   "source": [
    "Now let's look at how we can write yaml out to a file.\n",
    "\n",
    "We're going to start with the file `docker-compose.yaml` file which sets up a dockerized Redis database.\n",
    "\n",
    "We're going to read the data in, modify something and write it back out - to keep the original docker-compose file intact, I won't overwrite the original file, but instead write it to a copy until we have things ironed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257606ac-09e8-4157-a151-ba20a9ecd35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '3',\n",
       " 'services': {'redis': {'image': 'redis:latest',\n",
       "   'container_name': 'redis_queue',\n",
       "   'restart': 'always',\n",
       "   'ports': ['6379:6379'],\n",
       "   'command': 'redis-server --save 20 1 --loglevel warning --requirepass secret',\n",
       "   'volumes': ['data-volume:/data']}},\n",
       " 'volumes': {'data-volume': None}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('docker-compose.yaml') as f:\n",
    "    redis = yaml.safe_load(f)\n",
    "redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9d81b-d552-4588-ade9-f0025836c7bd",
   "metadata": {},
   "source": [
    "Now, let's say I need to modify the port mappings, and the container name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8315fb13-dbed-45e5-950c-ad42db688168",
   "metadata": {},
   "outputs": [],
   "source": [
    "redis[\"services\"][\"redis\"][\"container_name\"] = \"redis_instance_2\"\n",
    "redis[\"services\"][\"redis\"][\"ports\"] = [\"9000:6379\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a409b12e-7567-49f8-a1f9-f5f2afddb2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '3',\n",
       " 'services': {'redis': {'image': 'redis:latest',\n",
       "   'container_name': 'redis_instance_2',\n",
       "   'restart': 'always',\n",
       "   'ports': ['9000:6379'],\n",
       "   'command': 'redis-server --save 20 1 --loglevel warning --requirepass secret',\n",
       "   'volumes': ['data-volume:/data']}},\n",
       " 'volumes': {'data-volume': None}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87263ff-7c01-458a-a3c1-e0e629d52954",
   "metadata": {},
   "source": [
    "And let's write it out to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7ca5751-5f92-4015-bbf2-306d5bd41be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docker-compose.new.yaml\", \"w\") as f:\n",
    "    yaml.dump(redis, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8429d-e4b1-4808-8c37-d6335cb3de3e",
   "metadata": {},
   "source": [
    "Taking a look at the output file and we see this:\n",
    "```yaml\n",
    "services:\n",
    "  redis:\n",
    "    command: redis-server --save 20 1 --loglevel warning --requirepass secret\n",
    "    container_name: redis_instance_2\n",
    "    image: redis:latest\n",
    "    ports:\n",
    "    - 9000:6379\n",
    "    restart: always\n",
    "    volumes:\n",
    "    - data-volume:/data\n",
    "version: '3'\n",
    "volumes:\n",
    "  data-volume: null\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364be0a5-b876-4791-99e1-99504d0f5782",
   "metadata": {},
   "source": [
    "This is in contrast to how our original file looked:\n",
    "\n",
    "```yaml\n",
    "---\n",
    "version: '3'\n",
    "\n",
    "services:\n",
    "  redis:\n",
    "    image: redis:latest\n",
    "    container_name: redis_queue\n",
    "    restart: always\n",
    "    ports:\n",
    "      - '6379:6379'\n",
    "    command: redis-server --save 20 1 --loglevel warning --requirepass secret\n",
    "    volumes:\n",
    "      - data-volume:/data\n",
    "\n",
    "volumes:\n",
    "  data-volume:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710eaa37-bdf2-43a1-9331-0f23060d5746",
   "metadata": {},
   "source": [
    "The new version almost looks identical to our original version except our keys have been sorted (e.g. `version` is in the middle of the file, not at the top where we would like it to be, etc). Not also how our file started with some dashes (specifies an explicit document, whereas the newly created yaml file does not, i.e. it is an implicit document).\n",
    "\n",
    "Fortunately, `pyyaml` has different arguments we can use to control all this. In this case, we want to retain the ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "153ee261-e8d5-4a09-a8e7-5d906a745588",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docker-compose.new.yaml\", \"w\") as f:\n",
    "    yaml.dump(redis, f, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27ffad-6b8d-45d0-8cd6-077a78106866",
   "metadata": {},
   "source": [
    "And this now looks like this:\n",
    "\n",
    "```yaml\n",
    "version: '3'\n",
    "services:\n",
    "  redis:\n",
    "    image: redis:latest\n",
    "    container_name: redis_instance_2\n",
    "    restart: always\n",
    "    ports:\n",
    "    - 9000:6379\n",
    "    command: redis-server --save 20 1 --loglevel warning --requirepass secret\n",
    "    volumes:\n",
    "    - data-volume:/data\n",
    "volumes:\n",
    "  data-volume: null\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27fe74-6d73-4b80-ae80-d5c8bfff627e",
   "metadata": {},
   "source": [
    "Only thing missing is the fact that we had an explicit document - would be nice to preserve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad312aa-4fbe-437e-9047-a434e064034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docker-compose.new.yaml\", \"w\") as f:\n",
    "    yaml.dump(redis, f, sort_keys=False, explicit_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28946bda-00e8-4d2e-a834-89d1bf5fc8b9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `pyyaml` library has much more functionality than I cover here, but to get started reading and writing yaml files, what we covered here is more than sufficient. By all means, go check out the library docs and learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e98031-135f-4b7d-9fd9-e257488a643d",
   "metadata": {},
   "source": [
    "In future videos I'll show you a yaml query tool that we can use from Python - and since, as I showed earlier JSON is a subset of YAML, it can also be used as a JSON query tool. but that's for another day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0f029-9022-41f1-b1c1-d50d5f10709b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
